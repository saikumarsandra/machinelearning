# Machine Learning buzz words

**Bag of words**: A technique used to extract features from the text. It counts how many times a word appears in a document (corpus), and then transforms that information into a dataset.

A **categorical** label has a discrete set of possible values, such as "is a cat" and "is not a cat."

**Clustering**. Unsupervised learning task that helps to determine if there are any naturally occurring groupings in the data.

**CNN**: Convolutional Neural Networks (CNN) represent nested filters over grid-organized data. They are by far the most commonly used type of model when processing images.

A **continuous (regression)** label does not have a discrete set of possible values, which means possibly an unlimited number of possibilities.

**Data vectorization**: A process that converts non-numeric data into a numerical format so that it can be used by a machine learning model.

**Discrete:** A term taken from statistics referring to an outcome taking on only a finite number of values (such as days of the week).

******FFNN****: The most straightforward way of structuring a neural network, the Feed Forward Neural Network (FFNN) structures neurons in a series of layers, with each neuron in a layer containing weights to all neurons in the previous layer.

**Hyperparameters** are settings on the model which are not changed during training but can affect how quickly or how reliably the model trains, such as the number of clusters the model should identify.

**Log loss** is used to calculate how uncertain your model is about the predictions it is generating.

**Hyperplane:** A mathematical term for a surface that contains more than two planes.

**Impute** is a common term referring to different statistical tools which can be used to calculate missing values from your dataset.

****label** refers to data that already contains the solution.

**loss function** is used to codify the modelâ€™s distance from this goal

**Machine learning**, or ML, is a modern software development technique that enables computers to solve problems by using examples of real-world data.

**Model accuracy** is the fraction of predictions a model gets right. Discrete: A term taken from statistics referring to an outcome taking on only a finite number of values (such as days of the week). Continuous: Floating-point values with an infinite range of possible values. The opposite of categorical or discrete values, which take on a limited number of possible values.

**Model inference** is when the trained model is used to generate predictions.

**model** is an extremely generic program, made specific by the data used to train it.

**Model parameters** are settings or configurations the training algorithm can update to change how the model behaves.

**Model training algorithms work through an interactive process where the current model iteration is analyzed to determine what changes can be made to get closer to the goal. Those changes are made and the iteration continues until the model is evaluated to meet the goals.

**Neural networks**: a collection of very simple models connected together. These simple models are called neurons. The connections between these models are trainable model parameters called weights.

**Outliers** are data points that are significantly different from others in the same sample.

****Plane**: A mathematical term for a flat surface (like a piece of paper) on which two points can be joined by a straight line.

**Regression**: A common task in supervised machine learning.

In **reinforcement learning**, the algorithm figures out which actions to take in a situation to maximize a reward (in the form of a number) on the way to reaching a specific goal.

**RNN/LSTM**: Recurrent Neural Networks (RNN) and the related Long Short-Term Memory (LSTM) model types are structured to effectively represent for loops in traditional computing, collecting state while iterating over some object. They can be used for processing sequences of data.

**Silhouette coefficient**: A score from -1 to 1 describing the clusters found during modeling. A score near zero indicates overlapping clusters, and scores less than zero indicate data points assigned to incorrect clusters. A

**Stop words**: A list of words removed by natural language processing tools when building your dataset. There is no single universal list of stop words used by all-natural language processing tools.

In **supervised learning****, every training sample from the dataset has a corresponding label or output value associated with it. As a result, the algorithm learns to predict labels or output values.

****Test dataset**: The data withheld from the model during training, which is used to test how well your model will generalize to new data.


**Training dataset**: The data on which the model will be trained. Most of your data will be here.

**Transformer**: A more modern replacement for RNN/LSTMs, the transformer architecture enables training over larger datasets involving sequences of data.

In **unlabeled data**, you don't need to provide the model with any kind of label or solution while the model is being trained.

In **unsupervised learning**, there are no labels for the training data. A machine learning algorithm tries to learn the underlying patterns or distributions that govern the data.

**Agent:** The piece of software you are training is called an agent. It makes decisions in an environment to reach a goal.

**Environment:** The environment is the surrounding area with which the agent interacts.

**Reward:** Feedback is given to an agent for each action it takes in a given state. This feedback is a numerical reward.

**Action:** For every state, an agent needs to take an action toward achieving its goal.


**Exploration versus exploitation:** An agent should exploit known information from previous experiences to achieve higher cumulative rewards, but it also needs to explore to gain new experiences that can be used in choosing the best actions in the future.

**Discriminator:** A neural network trained to differentiate between real and synthetic data.

**Discriminator loss**: Evaluates how well the discriminator differentiates between real and fake data.

**Edit event**: When a note is either added or removed from your input track during inference.

**Environment:** The environment is the surrounding area within which the agent interacts.

**Generator:** A neural network that learns to create new data resembling the source data on which it was trained.

**Generator loss**: Measures how far the output data deviates from the real data present in the training dataset.

****Hidden layer:** A layer that occurs between the output and input layers. Hidden layers are tailored to a specific task.

**Input layer:** The first layer in a neural network. This layer receives all data that passes through the neural network.

**Output layer**: The last layer in a neural network. This layer is where the predictions are generated based on the information captured in the hidden layers.

**Piano roll:** A two-dimensional piano roll matrix that represents input tracks. Time is on the horizontal axis and pitch is on the vertical axis.

**Reward:** Feedback is given to an agent for each action it takes in a given state. This feedback is a numerical reward.



